{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(group):\n",
    "    features = {}\n",
    "    # Time window identifier\n",
    "    # features[\"timestamp\"] = group.name\n",
    "    \n",
    "    # Number of events\n",
    "    features[\"num_events\"] = len(group)\n",
    "    # Extract move events\n",
    "    move_events = group[group[\"event_type\"] == \"move\"]\n",
    "    features[\"num_moves\"] = len(move_events)\n",
    "    # Extract click events\n",
    "    click_events = group[group[\"event_type\"] == \"click\"]\n",
    "    features[\"num_clicks\"] = len(click_events)\n",
    "    # Extract scroll events\n",
    "    scroll_events = group[group[\"event_type\"] == \"scroll\"]\n",
    "    features[\"num_scrolls\"] = len(scroll_events)\n",
    "\n",
    "    # Compute movement distance and related features\n",
    "    if len(move_events) >= 2:\n",
    "        move_events = move_events.sort_values(\"time\")\n",
    "        x = move_events[\"x\"].values\n",
    "        y = move_events[\"y\"].values\n",
    "        t = move_events[\"time\"].values\n",
    "        dx = np.diff(x)\n",
    "        dy = np.diff(y)\n",
    "        dt = np.diff(t)\n",
    "        distances = np.sqrt(dx**2 + dy**2)\n",
    "        total_distance = np.sum(distances)\n",
    "        features[\"movement_distance\"] = total_distance\n",
    "\n",
    "        # Velocity calculations\n",
    "        velocities = distances / dt\n",
    "        features[\"velocity_mean\"] = np.mean(velocities)\n",
    "        features[\"velocity_max\"] = np.max(velocities)\n",
    "        features[\"velocity_min\"] = np.min(velocities)\n",
    "        features[\"velocity_sd\"] = np.std(velocities)\n",
    "        features[\"velocity_x_mean\"] = np.mean(dx / dt)\n",
    "        features[\"velocity_y_mean\"] = np.mean(dy / dt)\n",
    "\n",
    "        # Acceleration calculations\n",
    "        if len(velocities) >= 2:\n",
    "            dv = np.diff(velocities)\n",
    "            dv_dt = dv / dt[1:]  # Adjust time differences\n",
    "            features[\"acceleration_mean\"] = np.mean(dv_dt)\n",
    "            features[\"acceleration_max\"] = np.max(dv_dt)\n",
    "            features[\"acceleration_min\"] = np.min(dv_dt)\n",
    "            features[\"acceleration_sd\"] = np.std(dv_dt)\n",
    "\n",
    "            # Jerk calculations\n",
    "            if len(dv_dt) >= 2:\n",
    "                da = np.diff(dv_dt)\n",
    "                da_dt = da / dt[2:]\n",
    "                features[\"jerk_mean\"] = np.mean(da_dt)\n",
    "                features[\"jerk_sd\"] = np.std(da_dt)\n",
    "            else:\n",
    "                features[\"jerk_mean\"] = np.nan\n",
    "                features[\"jerk_sd\"] = np.nan\n",
    "        else:\n",
    "            features.update(\n",
    "                {\n",
    "                    \"acceleration_mean\": np.nan,\n",
    "                    \"acceleration_max\": np.nan,\n",
    "                    \"acceleration_min\": np.nan,\n",
    "                    \"acceleration_sd\": np.nan,\n",
    "                    \"jerk_mean\": np.nan,\n",
    "                    \"jerk_sd\": np.nan,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Angular velocity calculations\n",
    "        angles = np.arctan2(dy, dx)\n",
    "        d_angle = np.diff(angles)\n",
    "        d_angle = (d_angle + np.pi) % (2 * np.pi) - np.pi  # Normalize angles\n",
    "        angular_velocity = d_angle / dt[1:]\n",
    "        features[\"angular_velocity_mean\"] = np.mean(angular_velocity)\n",
    "        features[\"angular_velocity_sd\"] = np.std(angular_velocity)\n",
    "    else:\n",
    "        features.update(\n",
    "            {\n",
    "                \"movement_distance\": 0,\n",
    "                \"velocity_mean\": np.nan,\n",
    "                \"velocity_max\": np.nan,\n",
    "                \"velocity_min\": np.nan,\n",
    "                \"velocity_sd\": np.nan,\n",
    "                \"velocity_x_mean\": np.nan,\n",
    "                \"velocity_y_mean\": np.nan,\n",
    "                \"acceleration_mean\": np.nan,\n",
    "                \"acceleration_max\": np.nan,\n",
    "                \"acceleration_min\": np.nan,\n",
    "                \"acceleration_sd\": np.nan,\n",
    "                \"jerk_mean\": np.nan,\n",
    "                \"jerk_sd\": np.nan,\n",
    "                \"angular_velocity_mean\": np.nan,\n",
    "                \"angular_velocity_sd\": np.nan,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Movement duration\n",
    "    if len(move_events) >= 1:\n",
    "        features[\"movement_duration\"] = (\n",
    "            move_events[\"time\"].max() - move_events[\"time\"].min()\n",
    "        )\n",
    "    else:\n",
    "        features[\"movement_duration\"] = 0\n",
    "\n",
    "    # Pause time (idle cursor time)\n",
    "    total_time = group[\"time\"].max() - group[\"time\"].min()\n",
    "    features[\"total_time\"] = total_time\n",
    "    features[\"pause_time\"] = total_time - features[\"movement_duration\"]\n",
    "\n",
    "    # Flips (directional changes)\n",
    "    if len(move_events) >= 2 and len(dx) >= 2:\n",
    "        features[\"flips_x\"] = np.sum(np.diff(np.sign(dx)) != 0)\n",
    "        features[\"flips_y\"] = np.sum(np.diff(np.sign(dy)) != 0)\n",
    "    else:\n",
    "        features[\"flips_x\"] = 0\n",
    "        features[\"flips_y\"] = 0\n",
    "\n",
    "    # Number of pauses (idle periods)\n",
    "    if len(move_events) >= 2:\n",
    "        time_diffs = np.diff(move_events[\"time\"].values)\n",
    "        idle_threshold = 0.2  # Define a threshold for idle time\n",
    "        pauses = time_diffs[time_diffs > idle_threshold]\n",
    "        features[\"pause_count\"] = len(pauses)\n",
    "    else:\n",
    "        features[\"pause_count\"] = 0\n",
    "\n",
    "    # Hold time for clicks\n",
    "    if len(click_events) >= 1:\n",
    "        pressed_events = click_events[click_events[\"pressed\"] == True]\n",
    "        released_events = click_events[click_events[\"pressed\"] == False]\n",
    "        if len(pressed_events) == len(released_events):\n",
    "            hold_times = released_events[\"time\"].values - pressed_events[\"time\"].values\n",
    "            features[\"hold_time_mean\"] = np.mean(hold_times)\n",
    "            features[\"hold_time_sd\"] = np.std(hold_times)\n",
    "        else:\n",
    "            features[\"hold_time_mean\"] = np.nan\n",
    "            features[\"hold_time_sd\"] = np.nan\n",
    "    else:\n",
    "        features[\"hold_time_mean\"] = np.nan\n",
    "        features[\"hold_time_sd\"] = np.nan\n",
    "\n",
    "    return pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:227: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:219: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/df/fxnhsyqj16v2x3xg031vlyyr0000gn/T/ipykernel_16768/2018977831.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features_df = df.groupby('timestamp').apply(compute_features).reset_index(drop=True)\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:227: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/jangsus1/Homeworks/ML-Fall24-Team7/.ml/lib/python3.11/site-packages/numpy/_core/_methods.py:219: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to recordings/youtube_mouse_events_0_features.csv\n",
      "Features saved to recordings/web_browsing_mouse_events_0_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/fxnhsyqj16v2x3xg031vlyyr0000gn/T/ipykernel_16768/2018977831.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features_df = df.groupby('timestamp').apply(compute_features).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "files = glob('recordings/*.txt')\n",
    "\n",
    "for file in files:\n",
    "    events = []\n",
    "    monitors = []\n",
    "    with open(file, 'r') as f:\n",
    "        monitors.append(ast.literal_eval(f.readline().strip()))\n",
    "        for line in f:\n",
    "            event = ast.literal_eval(line.strip())\n",
    "            events.append(event)\n",
    "\n",
    "    # Convert events to a list of dictionaries\n",
    "    width, height = monitors[0][1], monitors[0][2]\n",
    "    event_list = []\n",
    "    for event in events:\n",
    "        if event[0] == 'move':\n",
    "            event_dict = {'event_type': 'move', 'time': event[1], 'x': event[2]/width, 'y': event[3]/height}\n",
    "        elif event[0] == 'click':\n",
    "            event_dict = {'event_type': 'click', 'time': event[1], 'x': event[2]/width, 'y': event[3]/height,\n",
    "                        'button': event[4], 'pressed': event[5]}\n",
    "        elif event[0] == 'scroll':\n",
    "            event_dict = {'event_type': 'scroll', 'time': event[1], 'x': event[2]/width, 'y': event[3]/height,\n",
    "                        'dx': event[4], 'dy': event[5]}\n",
    "        else:\n",
    "            continue\n",
    "        event_list.append(event_dict)\n",
    "\n",
    "    # Convert to DataFrame and sort by time\n",
    "    df = pd.DataFrame(event_list)\n",
    "    df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Organize events into time windows\n",
    "    start_time = df['time'].min()\n",
    "    df['timestamp'] = ((df['time'] - start_time) // 0.1).astype(int)\n",
    "\n",
    "    # Step 3: Extract features for each time window\n",
    "    # Apply the feature extraction function to each time window\n",
    "    features_df = df.groupby('timestamp').apply(compute_features).reset_index(drop=True)\n",
    "\n",
    "    features_df.to_csv(file.replace('.txt', '_features.csv'), index=False)\n",
    "    print(f\"Features saved to {file.replace('.txt', '_features.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/fxnhsyqj16v2x3xg031vlyyr0000gn/T/ipykernel_16768/2040813481.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/df/fxnhsyqj16v2x3xg031vlyyr0000gn/T/ipykernel_16768/2040813481.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(715, 280) (715,) (179, 280) (179,)\n",
      "X_train shape: (715, 280)\n",
      "X_test shape: (179, 280)\n",
      "F1 Score: 1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def process_class_data(file, label, K):\n",
    "    df = pd.read_csv(file)\n",
    "    df['label'] = label\n",
    "    # Handle missing values\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    df = df.dropna()\n",
    "    # Extract windows\n",
    "    windows = []\n",
    "    num_rows = df.shape[0]\n",
    "    for i in range(0, num_rows - K + 1):\n",
    "        window = df.iloc[i:i+K]\n",
    "        # Extract features\n",
    "        features = window.values.flatten()\n",
    "        windows.append(features)\n",
    "    return windows\n",
    "\n",
    "# Define the class files and window length\n",
    "class_files = {\n",
    "    0: '/Users/jangsus1/Homeworks/ML-Fall24-Team7/recordings/web_browsing_mouse_events_0_features.csv',\n",
    "    1: '/Users/jangsus1/Homeworks/ML-Fall24-Team7/recordings/youtube_mouse_events_0_features.csv',\n",
    "}\n",
    "K = 10  # Window length\n",
    "\n",
    "# Process the data for each class\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for label, file in class_files.items():\n",
    "    windows = process_class_data(file, label, K)\n",
    "    index = int(0.8 * len(windows))\n",
    "    X_train.extend(windows[:index])\n",
    "    X_test.extend(windows[index:])\n",
    "    y_train.extend([label] * index)\n",
    "    y_test.extend([label] * (len(windows) - index))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "\n",
    "# normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Train the Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate performance\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
